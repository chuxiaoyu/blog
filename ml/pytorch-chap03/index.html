<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="generator" content="mkdocs-1.4.3, mkdocs-terminal-4.4.0">
     
     
    <link rel="icon" type="image/png" sizes="192x192" href="../../img/android-chrome-192x192.png" />
<link rel="icon" type="image/png" sizes="512x512" href="../../img/android-chrome-512x512.png" />
<link rel="apple-touch-icon" sizes="180x180" href="../../img/apple-touch-icon.png" />
<link rel="shortcut icon" type="image/png" sizes="48x48" href="../../img/favicon.ico" />
<link rel="icon" type="image/png" sizes="16x16" href="../../img/favicon-16x16.png" />
<link rel="icon" type="image/png" sizes="32x32" href="../../img/favicon-32x32.png" />


    
 
<title>Chapter03 PyTorch的主要组成模块 - 起身獨立向荒原。</title>


<link href="../../css/fontawesome/css/fontawesome.min.css" rel="stylesheet">
<link href="../../css/fontawesome/css/solid.min.css" rel="stylesheet">
<link href="../../css/normalize.css" rel="stylesheet">
<link href="../../css/terminal.css" rel="stylesheet">
<link href="../../css/theme.css" rel="stylesheet">
<link href="../../css/theme.tile_grid.css" rel="stylesheet">
<link href="../../css/theme.footer.css" rel="stylesheet">
<!-- default color palette -->
<link href="../../css/palettes/default.css" rel="stylesheet">

<!-- page layout -->
<style>
/* initially set page layout to a one column grid */
.terminal-mkdocs-main-grid {
    display: grid;
    grid-column-gap: 1.4em;
    grid-template-columns: auto;
    grid-template-rows: auto;
}

/*  
*   when side navigation is not hidden, use a two column grid.  
*   if the screen is too narrow, fall back to the initial one column grid layout.
*   in this case the main content will be placed under the navigation panel. 
*/
@media only screen and (min-width: 70em) {
    .terminal-mkdocs-main-grid {
        grid-template-columns: 4fr 9fr;
    }
}</style>

<!-- link underline override -->
<style>
#terminal-mkdocs-main-content a:not(.headerlink){
    text-decoration: none;
}
</style>

     
    
    

    
    <!-- search css support -->
<link href="../../css/search/bootstrap-modal.css" rel="stylesheet">
<!-- search scripts -->
<script>
    var base_url = "../..",
    shortcuts = "{}";
</script>
<script src="../../js/jquery/jquery-1.10.1.min.js" defer></script>
<script src="../../js/bootstrap/bootstrap.min.js" defer></script>
<script src="../../js/mkdocs/base.js" defer></script>
    
    
    
    
    <script src="../../js/extra.js"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <script src="../../search/main.js"></script>
    

    
</head>

<body class="terminal"><div class="container">
    <div class="terminal-nav">
        <header class="terminal-logo">
            <div id="mkdocs-terminal-site-name" class="logo terminal-prompt"><a href="/" class="no-style">起身獨立向荒原。</a></div>
        </header>
        
        <nav class="terminal-menu">
            
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                
                <li property="itemListElement" typeof="ListItem">
                    <a href="../.." class="menu-item " property="item" typeof="WebPage">
                        <span property="name">Home</span>
                    </a>
                    <meta property="position" content="0">
                </li>
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                
                    
                    


<li property="itemListElement" typeof="ListItem">
    <a href="#" class="menu-item" data-toggle="modal" data-target="#mkdocs_search_modal" property="item" typeof="SearchAction">
        <i aria-hidden="true" class="fa fa-search"></i> <span property="name">Search</span>
    </a>
    <meta property="position" content="1">
</li>
                    
            </ul>
            
        </nav>
    </div>
</div>
        
    <div class="container">
        <div class="terminal-mkdocs-main-grid"><aside id="terminal-mkdocs-side-panel"><nav>
  
    <ul class="terminal-mkdocs-side-nav-items">
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../..">Home</a>
        
    
    
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">Deep Learning for Time Series Forecasting</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../time-series/01-time-series-types/">1.Taxonomy of Time Series Forecasting</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../time-series/02-time-series-supervised-learning/">2.Transforming Time Series to Supervised Learning</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../time-series/03-mlp-time-series-forecasting/">3.MLP for Time Series Forecasting</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">Python</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../python/ontology-with-python/">Ontology with Python</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">CS224n自然语言处理</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../Lecture07/">Lecture07 机器翻译、seq2seq模型、注意力机制</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../Lecture09/">Lecture09 自注意力模型、Transformers</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../Lecture10/">Lecture10 预训练</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../Lecture11/">Lecture11 问答系统</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">基于transformers的NLP</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task01/">Task01 NLP学习概览</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task02/">Task02 学习Attentioin和Transformer</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task03/">Task03 学习BERT</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task04/">Task04 学习GPT</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task05/">Task05 编写BERT模型</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task06/">Task06 BERT应用、训练和优化</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../nlp-transformer-task07/">Task07 使用Transformers解决文本分类任务</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index">深入浅出PyTorch</span>
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../pytorch-chap01-02/">Chapter01-02 PyTorch的简介和安装、PyTorch基础知识</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        <span class="

    terminal-mkdocs-side-nav-item--active">Chapter03 PyTorch的主要组成模块</span>
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../pytorch-chap04/">Chapter04 PyTorch基础实战——FashionMNIST图像分类</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">Nand2Tetris 计算机系统要素</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/nand2tetris_part_1/">Nand2Tetris Part1 (Hardware)</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/nand2tetris_part_2/">Nand2Tetris Part2 (Software)</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">ML Compilation 机器学习编译</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/ml-compilation-01/">01 机器学习编译概述</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/ml-compilation-02/">02 张量程序抽象</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/ml-compilation-03/">03 张量程序抽象案例研究：TensorIR</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/ml-compilation-04/">04 端到端模型整合</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../system/ml-compilation-05/">05 自动程序优化</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">Resources</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../resource/ml-system-learning-list/">ML System Learning List</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../resource/open-source-projects/">Open Source Projects</a>
        
    
    </li>
            
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../resource/post-types-of-paper/">Types of CS Paper</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
          



<li class="terminal-mkdocs-side-nav-li">
    
    
        
        
            
                
        

        
            
    
        
        
            
            
            <span class="
        
            
        
    

    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index">Philosophy</span>
        
    
    
        
      
        
            <ul class="terminal-mkdocs-side-nav-li-ul">
        
            
            
                
                
            

             
                <li class="terminal-mkdocs-side-nav-li-ul-li">
    
        
        
            <a class="

    terminal-mkdocs-side-nav-item" href="../../philosophy/40-philosophers/">A Quick Introduction to 40+ Philosophers</a>
        
    
    </li>
            
            
    </ul>
        
    
  </li>
        
    </ul>
  
</nav><hr>
<nav>
    <ul>
        <li><a href="#pytorch">第三章 PyTorch的主要组成模块</a></li>
        <li><a href="#_1">完成深度学习的必要部分</a></li>
        <li><a href="#_2">基本配置</a></li>
        <li><a href="#_3">数据加载和处理</a></li>
        <li><a href="#_4">模型构建</a></li>
        <li><a href="#_5">神经网络的构造</a></li>
        <li><a href="#_6">神经网络中常见的层</a></li>
        <li><a href="#_7">不含模型参数的层</a></li>
        <li><a href="#_8">含模型参数的层</a></li>
        <li><a href="#_9">二维卷积层</a></li>
        <li><a href="#_10">池化层</a></li>
        <li><a href="#lenet">模型示例：LeNet</a></li>
        <li><a href="#alexnet">模型示例：AlexNet</a></li>
        <li><a href="#_11">损失函数</a></li>
        <li><a href="#_12">二分类交叉熵损失函数</a></li>
        <li><a href="#_13">其他损失函数</a></li>
        <li><a href="#_14">优化器</a></li>
        <li><a href="#_15">什么是优化器</a></li>
        <li><a href="#pytorch_1">PyTorch提供的优化器</a></li>
        <li><a href="#_16">训练与评估</a></li>
        <li><a href="#_17">可视化</a></li>
        <li><a href="#_18">参考资料</a></li>
        
    </ul>
</nav>
</aside>
            <main id="terminal-mkdocs-main-content">
    
    
    
    
    

<section id="mkdocs-terminal-content">
    <h6 id="pytorch">第三章 PyTorch的主要组成模块<a class="headerlink" href="#pytorch" title="Permanent link">&para;</a></h6>
<h6 id="_1">完成深度学习的必要部分<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h6>
<p>机器学习：</p>
<ol>
<li>数据预处理（数据格式、数据转换、划分数据集）</li>
<li>选择模型，设定损失和优化函数，设置超参数</li>
<li>训练模型，拟合训练集</li>
<li>评估模型，在并在验证集/测试集上计算模型表现</li>
</ol>
<p>深度学习的注意事项：</p>
<ol>
<li>数据预处理（数据加载、批处理）</li>
<li>逐层搭建模型，组装不同模块</li>
<li>GPU的配置和操作</li>
</ol>
<p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/11_dnn.jpg?raw=true" width="600" alt="" align="center" /></p>
<h6 id="_2">基本配置<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h6>
<p>导入必须的包：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optimizer</span>
</span></code></pre></div>
<p>超参数设置：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># batch size</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span>  <span class="c1"># 初始学习率</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># 训练次数 </span>
</span></code></pre></div>
<p>GPU的设置：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># 方案一：使用os.environ，这种情况如果使用GPU不需要设置</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0,1&#39;</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h6 id="_3">数据加载和处理<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h6>
<p>PyTorch数据读入是通过Dataset+Dataloader的方式完成的，Dataset定义好数据的格式和数据变换形式，Dataloader用iterative的方式不断读入批次数据。</p>
<p>我们可以定义自己的Dataset类来实现灵活的数据读取，定义的类需要继承PyTorch自身的Dataset类。主要包含三个函数：</p>
<ul>
<li><code>__init__</code>: 用于向类中传入外部参数，同时定义样本集</li>
<li><code>__getitem__</code>: 用于逐个读取样本集合中的元素，可以进行一定的变换，并将返回训练/验证所需的数据</li>
<li><code>__len__</code>: 用于返回数据集的样本数</li>
</ul>
<p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/12_dataset.jpg?raw=true" width="600" alt="" align="center" /></p>
<ul>
<li>batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数</li>
<li>num_workers：有多少个进程用于读取数据</li>
<li>shuffle：是否将读入的数据打乱</li>
<li>drop_last：对于样本最后一部分没有达到批次数的样本，不再参与训练</li>
</ul>
<p>下面是本部分代码在notebook中的运行情况。主要参考 PyTorch官方教程中文版 <a href="https://pytorch123.com/SecondSection/training_a_classifier/">https://pytorch123.com/SecondSection/training_a_classifier/</a></p>
<p><img src="https://github.com/chuxiaoyu/blog_image/blob/master/pytorch/chap03.jpg?raw=true" width="" alt="" align="center" /></p>
<h6 id="_4">模型构建<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h6>
<h6 id="_5">神经网络的构造<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h6>
<p>PyTorch中神经网络构造一般是基于 Module 类的模型来完成的。Module 类是 nn 模块里提供的一个模型构造类，是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型。下面继承 Module 类构造多层感知机（MLP）。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>  <span class="c1"># 声明带有模型参数的层，这里声明了两个全连接层</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="c1"># 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例例时还可以指定其他函数</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>   <span class="c1"># 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>    <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
</span></code></pre></div>
<p>我们可以实例化 MLP 类得到模型变量 net 。下⾯的代码初始化 net 并传入输⼊数据 X 做一次前向计算。其中， net(X) 会调用 MLP 继承⾃自 Module 类的 <strong>call</strong> 函数，这个函数将调⽤用 MLP 类定义的forward 函数来完成前向计算。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3277</span><span class="p">,</span> <span class="mf">0.2204</span><span class="p">,</span> <span class="mf">0.5239</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.4333</span><span class="p">,</span> <span class="mf">0.1906</span><span class="p">,</span> <span class="mf">0.1318</span><span class="p">],</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>        <span class="p">[</span><span class="mf">0.9850</span><span class="p">,</span> <span class="mf">0.2121</span><span class="p">,</span> <span class="mf">0.8405</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.3796</span><span class="p">,</span> <span class="mf">0.2717</span><span class="p">,</span> <span class="mf">0.5553</span><span class="p">]])</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="o">&gt;&gt;&gt;</span> 
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="o">...</span>   <span class="c1"># 声明带有模型参数的层，这里声明了两个全连接层</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="o">...</span>   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="o">...</span>     <span class="c1"># 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例例时还可以指定其他函数</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="o">...</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="o">...</span>     <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="o">...</span>     <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a><span class="o">...</span>     <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a><span class="o">...</span>     
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a><span class="o">...</span>    <span class="c1"># 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出</span>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span class="o">...</span>   <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a><span class="o">...</span>     <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a><span class="o">...</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a><span class="o">...</span> 
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a><span class="n">MLP</span><span class="p">(</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>  <span class="p">(</span><span class="n">hidden</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>  <span class="p">(</span><span class="n">act</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">()</span>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a><span class="p">)</span>
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a><span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.1317</span><span class="p">,</span>  <span class="mf">0.0702</span><span class="p">,</span>  <span class="mf">0.1707</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0081</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2730</span><span class="p">,</span>  <span class="mf">0.2837</span><span class="p">,</span>  <span class="mf">0.0700</span><span class="p">,</span>  <span class="mf">0.1718</span><span class="p">,</span>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>          <span class="mf">0.0299</span><span class="p">,</span>  <span class="mf">0.2082</span><span class="p">],</span>
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>        <span class="p">[</span> <span class="mf">0.1094</span><span class="p">,</span>  <span class="mf">0.0936</span><span class="p">,</span>  <span class="mf">0.2474</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0139</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1861</span><span class="p">,</span>  <span class="mf">0.1846</span><span class="p">,</span>  <span class="mf">0.1658</span><span class="p">,</span>  <span class="mf">0.2051</span><span class="p">,</span>
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>          <span class="mf">0.2609</span><span class="p">,</span>  <span class="mf">0.2227</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">AddmmBackward</span><span class="o">&gt;</span><span class="p">)</span>
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a><span class="o">&gt;&gt;&gt;</span> 
</span></code></pre></div>
<h6 id="_6">神经网络中常见的层<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h6>
<h6 id="_7">不含模型参数的层<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h6>
<p>下⾯构造的 MyLayer 类通过继承 Module 类自定义了一个**将输入减掉均值后输出**的层。这个层里不含模型参数。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="o">&gt;&gt;&gt;</span> 
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="o">...</span>     <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="o">...</span>         <span class="nb">super</span><span class="p">(</span><span class="n">MyLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="o">...</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="o">...</span>         <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="o">...</span> 
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span> <span class="o">=</span> <span class="n">MyLayer</span><span class="p">()</span>  <span class="c1"># 实例化该层</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="n">MyLayer</span><span class="p">()</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">])</span>
</span></code></pre></div>
<h6 id="_8">含模型参数的层<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h6>
<p>我们还可以自定义含模型参数的自定义层。其中的模型参数可以通过训练学出。</p>
<p>Parameter 类其实是 Tensor 的子类，如果一 个 Tensor 是 Parameter ，那么它会⾃动被添加到模型的参数列表里。所以在⾃定义含模型参数的层时，我们应该将参数定义成 Parameter ，除了直接定义成 Parameter 类外，还可以使⽤ ParameterList 和 ParameterDict 分别定义参数的列表和字典。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="k">class</span> <span class="nc">MyListDense</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">MyListDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)):</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">MyListDense</span><span class="p">()</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span class="n">MyListDense</span><span class="p">(</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>  <span class="p">(</span><span class="n">params</span><span class="p">):</span> <span class="n">ParameterList</span><span class="p">(</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>      <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>      <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x1</span><span class="p">]</span>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>  <span class="p">)</span>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a><span class="p">)</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="k">class</span> <span class="nc">MyDictDense</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">MyDictDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">({</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>                <span class="s1">&#39;linear1&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>                <span class="s1">&#39;linear2&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>        <span class="p">})</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;linear3&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))})</span> <span class="c1"># 新增</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">choice</span><span class="o">=</span><span class="s1">&#39;linear1&#39;</span><span class="p">):</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">choice</span><span class="p">])</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">MyDictDense</span><span class="p">()</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="n">MyDictDense</span><span class="p">(</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>  <span class="p">(</span><span class="n">params</span><span class="p">):</span> <span class="n">ParameterDict</span><span class="p">(</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>      <span class="p">(</span><span class="n">linear1</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>      <span class="p">(</span><span class="n">linear2</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x1</span><span class="p">]</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>      <span class="p">(</span><span class="n">linear3</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">containing</span><span class="p">:</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x2</span><span class="p">]</span>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a>  <span class="p">)</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a><span class="p">)</span>
</span></code></pre></div>
<p>下面给出常见的神经网络的一些层，比如卷积层、池化层，以及较为基础的AlexNet，LeNet等。</p>
<h6 id="_9">二维卷积层<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h6>
<p>二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="c1"># 卷积运算（二维互相关）</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="k">def</span> <span class="nf">corr2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span> 
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">X</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">K</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>            <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">j</span> <span class="o">+</span> <span class="n">w</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>    <span class="k">return</span> <span class="n">Y</span>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a><span class="c1"># 二维卷积层</span>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a><span class="k">class</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">))</span>
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>        <span class="k">return</span> <span class="n">corr2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</span></code></pre></div>
<p>填充(padding)是指在输⼊入⾼高和宽的两侧填充元素(通常是0元素)。</p>
<p>在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下 的顺序，依次在输⼊数组上滑动。我们将每次滑动的行数和列数称为步幅(stride)。</p>
<p>（skip）</p>
<h6 id="_10">池化层<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h6>
<p>池化层每次对输入数据的一个固定形状窗口(⼜称池化窗口)中的元素计算输出。不同于卷积层里计算输⼊和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也 分别叫做最大池化或平均池化。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="o">&gt;&gt;&gt;</span> 
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">):</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="o">...</span>     <span class="n">p_h</span><span class="p">,</span> <span class="n">p_w</span> <span class="o">=</span> <span class="n">pool_size</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="o">...</span>     <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">p_h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">p_w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a><span class="o">...</span>     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="o">...</span>         <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a><span class="o">...</span>             <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="o">...</span>                 <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">p_h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">j</span> <span class="o">+</span> <span class="n">p_w</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a><span class="o">...</span>             <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;avg&#39;</span><span class="p">:</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a><span class="o">...</span>                 <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">p_h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">j</span> <span class="o">+</span> <span class="n">p_w</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a><span class="o">...</span>     <span class="k">return</span> <span class="n">Y</span>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a><span class="o">...</span> 
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a><span class="n">array</span><span class="p">([[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>       <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]])</span>
</span></code></pre></div>
<h6 id="lenet">模型示例：LeNet<a class="headerlink" href="#lenet" title="Permanent link">&para;</a></h6>
<p>（待补充）</p>
<h6 id="alexnet">模型示例：AlexNet<a class="headerlink" href="#alexnet" title="Permanent link">&para;</a></h6>
<p>（待补充）</p>
<h6 id="_11">损失函数<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h6>
<p>一个好的训练离不开优质的负反馈，这里的损失函数就是模型的负反馈。</p>
<p>这里将列出PyTorch中常用的损失函数（一般通过torch.nn调用），并详细介绍每个损失函数的功能介绍、数学公式和调用代码。</p>
<h6 id="_12">二分类交叉熵损失函数<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h6>
<p><code>torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')</code></p>
<p><strong>功能</strong>：计算二分类任务时的交叉熵（Cross Entropy）函数。在二分类中，label是{0,1}。对于进入交叉熵函数的input为概率分布的形式。一般来说，input为sigmoid激活层的输出，或者softmax的输出。</p>
<p><strong>主要参数</strong>：</p>
<ul>
<li><code>weight</code>:每个类别的loss设置权值</li>
<li><code>size_average</code>:数据为bool，为True时，返回的loss为平均值；为False时，返回的各样本的loss之和.</li>
<li><code>reduce</code>:数据类型为bool，为True时，loss的返回是标量。</li>
</ul>
<h6 id="_13">其他损失函数<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h6>
<p>交叉熵损失函数</p>
<p>L1损失函数</p>
<p>MSE损失函数</p>
<p>平滑L1 (Smooth L1)损失函数</p>
<p>目标泊松分布的负对数似然损失</p>
<p>KL散度</p>
<h6 id="_14">优化器<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h6>
<h6 id="_15">什么是优化器<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h6>
<p>深度学习的目标是通过不断改变网络参数，使得参数能够对输入做各种非线性变换拟合输出，本质上就是一个函数去寻找最优解，只不过这个最优解使一个矩阵。那么我们如何计算出来这么多的系数，有以下两种方法：</p>
<ol>
<li>第一种是最直接的暴力穷举一遍参数，这种方法的实施可能性基本为0，堪比愚公移山plus的难度。</li>
<li>为了使求解参数过程更加快，人们提出了第二种办法，即就是是BP+优化器逼近求解。</li>
</ol>
<p>因此，优化器就是根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值，使得模型输出更加接近真实标签。</p>
<h6 id="pytorch_1">PyTorch提供的优化器<a class="headerlink" href="#pytorch_1" title="Permanent link">&para;</a></h6>
<p>Pytorch很人性化的给我们提供了一个优化器的库torch.optim，在这里面给我们提供了十种优化器。</p>
<ul>
<li>torch.optim.ASGD</li>
<li>torch.optim.Adadelta</li>
<li>torch.optim.Adagrad</li>
<li>torch.optim.Adam</li>
<li>torch.optim.AdamW</li>
<li>torch.optim.Adamax</li>
<li>torch.optim.LBFGS</li>
<li>torch.optim.RMSprop</li>
<li>torch.optim.Rprop</li>
<li>torch.optim.SGD</li>
<li>torch.optim.SparseAdam</li>
</ul>
<h6 id="_16">训练与评估<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h6>
<p>完成了上述设定后就可以加载数据开始训练模型了。首先应该设置模型的状态：如果是训练状态，那么模型的参数应该支持反向传播的修改；如果是验证/测试状态，则不应该修改模型参数。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>   <span class="c1"># 训练状态</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>   <span class="c1"># 验证/测试状态</span>
</span></code></pre></div>
<p>训练过程：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>  <span class="c1"># 此时要用for循环读取DataLoader中的全部数据。</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>        <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">label</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>  <span class="c1"># 之后将数据放到GPU上用于后续计算，此处以.cuda()为例</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># 开始用当前批次数据做训练时，应当先将优化器的梯度置零</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># 之后将data送入模型中训练</span>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>   <span class="c1"># 根据预先定义的criterion计算损失函数</span>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># 将loss反向传播回网络</span>
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># 使用优化器更新模型参数</span>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">))</span>
</span></code></pre></div>
<p>验证/测试的流程基本与训练过程一致，不同点在于：</p>
<ul>
<li>需要预先设置torch.no_grad，以及将model调至eval模式</li>
<li>不需要将优化器的梯度置零</li>
<li>不需要将loss反向回传到网络</li>
<li>不需要更新optimizer</li>
</ul>
<p>验证/测试过程：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="k">def</span> <span class="nf">val</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>       
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>    <span class="n">val_loss</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>            <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">label</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>            <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>            <span class="n">running_accu</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Training Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">))</span>
</span></code></pre></div>
<h6 id="_17">可视化<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h6>
<p>在PyTorch深度学习中，可视化是一个可选项，指的是某些任务在训练完成后，需要对一些必要的内容进行可视化，比如分类的ROC曲线，卷积网络中的卷积核，以及训练/验证过程的损失函数曲线等等。</p>
<h6 id="_18">参考资料<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h6>
<ul>
<li>Datawhale开源项目：深入浅出PyTorch <a href="https://github.com/datawhalechina/thorough-pytorch/">https://github.com/datawhalechina/thorough-pytorch/</a></li>
<li>李宏毅机器学习2021春-PyTorch Tutorial <a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=5">https://www.bilibili.com/video/BV1Wv411h7kN?p=5</a></li>
<li>动手学深度学习pytorch版 <a href="https://zh-v2.d2l.ai/chapter_preface/index.html">https://zh-v2.d2l.ai/chapter_preface/index.html</a></li>
<li>PyTorch官方教程中文版 <a href="https://pytorch123.com/SecondSection/training_a_classifier/">https://pytorch123.com/SecondSection/training_a_classifier/</a></li>
</ul>
</section>

<section id="mkdocs-terminal-after-content">
    
</section>
<section id="mkdocs-terminal-revision">
<br>
<aside>
    <p>
        <small>
            <i>Page last updated 2023-12-10. </i>
        </small>
    </p>
</aside>
</section>
            </main>
        </div>
        <hr><footer>
    <div class="terminal-mkdocs-footer-grid">
        <div id="terminal-mkdocs-footer-copyright-info">
            
            <p class="text-center text-muted">&copy; 2022-2023 by <a href='https://chuxiaoyu.github.io/' target='_blank'> Xiaoyu Chu </a></p>
             Site built with <a href="http://www.mkdocs.org">MkDocs</a> and <a href="https://github.com/ntno/mkdocs-terminal">Terminal for MkDocs</a>.
        </div>
        <div id="terminal-mkdocs-footer-prev-next">
            <nav class="btn-group">
                <a href="../pytorch-chap01-02/" title="Chapter01-02 PyTorch的简介和安装、PyTorch基础知识">Previous</a>
                |
                <a href="../pytorch-chap04/" title="Chapter04 PyTorch基础实战——FashionMNIST图像分类">Next</a>
            </nav>
        </div>
    </div>
</footer>
    </div>

    
    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="alertdialog" aria-modal="true" aria-labelledby="searchModalLabel">
    <div class="modal-dialog modal-lg" role="search">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="searchModalLabel">Search</h5>
                <button type="button" class="close btn btn-default btn-ghost" data-dismiss="modal"><span aria-hidden="true">x</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p id="searchInputLabel">Type to start searching</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" aria-labelledby="searchInputLabel" placeholder="" id="mkdocs-search-query" title="Please enter search terms here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No document matches found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    
    
</body>

</html>